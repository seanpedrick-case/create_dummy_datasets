import pandas as pd
import tools.funcs as funcs
import gradio as gr

"""
All versions 1.3 and before credited to Daniel Mead
V1.3
Added ability to customise frame names and number

V1.1 
Added ground truth frame, includes original, un-noised entries. These are no longer present in the original frames
This means there is roughly a 25% chance of an entry being included un-noised. 
There is now 0% chance of 0 repeats, 30% of 1, 30% of 2, 20% 3 etc. to account for the removal of ground truth values.

V1.0

Generates 10,000 people

50/50 gender split
10% include titles on the first name (only one first name at a time at the moment)
Birth Dates are all post 1950, randomly distributed
Addresses are randomly generated by faker.
    Cities are: 20 fake cities (1), Cardiff (2), Birmingham (3), Manchester (3), Durham (1), and London (6)
        Numbers in brackets above indicate weightings. IE 5x more likely to be in London than random city.
Postcodes are randomly generated, and are unrelated to addresses (no way of linking these for realism, currently)

For each repeat, all property have a 20% change to have one type of noise added (via typo library). 
Also have a further 20% chance for a second type of noise if one is already added (4% chance total).
Each property has an equal chance and they are non-exclusive. Ie. 0.2^n chance that n properties have errors.

The list of data is then split into 3 randomly sized (20-40% each) frames, which are randomised.

Each item contains a property called group which indicates its ground truth grouping.

"""
#### Opts
num_people = 10000
frames = 2 # names for frames

#num_repeats = [1, 2, 3, 4, 5] 
#repeat_weights = [3, 6, 8, 9, 10] # Cumulative weights. Ie. 30% of 1 repeat, 30% chance of 2, 20% of 3


#data_frame_list, out_message = funcs.create_fake_df(num_people, frames, faker_country, add_group, overwrite_ground_truth)

#print(out_message)

#for n, frame in enumerate(data_frame_list):
#    frame.to_csv(f"{frames[n]}_frame.csv")


def detect_file_type(filename):
    """Detect the file type based on its extension."""
    if (filename.endswith('.csv')) | (filename.endswith('.csv.gz')) | (filename.endswith('.zip')):
        return 'csv'
    elif filename.endswith('.xlsx'):
        return 'xlsx'
    elif filename.endswith('.parquet'):
        return 'parquet'
    else:
        raise ValueError("Unsupported file type.")

def read_file(filename):
    """Read the file based on its detected type."""
    file_type = detect_file_type(filename)
    
    if file_type == 'csv':
        return pd.read_csv(filename, low_memory=False)
    elif file_type == 'xlsx':
        return pd.read_excel(filename)
    elif file_type == 'parquet':
        return pd.read_parquet(filename)

def put_columns_in_df(in_file):
    new_choices = []
    concat_choices = []
    
    for file in in_file:
        df = read_file(file.name)
        new_choices = list(df.columns)

        concat_choices.extend(new_choices)     
        
    return gr.Dropdown(choices=concat_choices, value=concat_choices)

def dummy_function(in_colnames):
    """
    A dummy function that exists just so that dropdown updates work correctly.
    """
    return None    

''' Create the gradio interface '''

block = gr.Blocks(theme = gr.themes.Base())

with block:
    gr.Markdown(
    """
    # Create fake datasets
    """)

    with gr.Row():
        number_of_people = gr.Slider(label = "Number of people to create", value=num_people, minimum=1000, maximum=100000, step=1000)

        number_of_frames = gr.Slider(label = "Number of data frames to create", value=frames, minimum=1, maximum=10, step=1)

    with gr.Row():
        percentage_overlap = gr.Slider(label = "What percentage of people in the smallest data frame are duplicated across all data frames?", value=1, minimum=0, maximum=1, step=0.1)

        random_seed = gr.Number(label="Choose random seed", value=42)
    
    create_df_btn = gr.Button("Create fake data")
    
    with gr.Row():
        output_summary = gr.Textbox(label="Output result")
        output_file = gr.File(label="Output file")
        
    # Updates to components

    create_df_btn.click(fn=funcs.create_fake_df, inputs=[number_of_people, number_of_frames, percentage_overlap, random_seed],
                        outputs=[output_file, output_summary], api_name="faker")
    
block.queue(concurrency_count=1).launch(debug=True)